{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  T-tests and P-values\n",
    "\n",
    "In statistics, t-test is used to test if two data samples have a significant difference between their means. There are two types of t-test:\n",
    "\n",
    "* **Student's t-test** (a.k.a. independent or uncorrelated t-test). This type of t-test is to compare the samples of **two independent populations** (e.g. test scores of students in two different classes). `scipy` provides the [`ttest_ind`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_ind.html) method to conduct student's t-test.\n",
    "\n",
    "* **Paired t-test** (a.k.a. dependent or correlated t-test). This type of t-test is to compare the samples of **the same population** (e.g. scores of different tests of students in the same class). `scipy` provides the [`ttest_rel`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ttest_rel.html) method to conduct paired t-test.\n",
    "\n",
    "Both types of t-tests return a number which is called the **p-value**. If p-value is below 0.05, we can confidently declare the null-hypothesis is rejected and the difference is significant. If p-value is between 0.05 and 0.1, we may also declare the null-hypothesis is rejected but we are not highly confident. If p-value is above 0.1 we do not reject the null-hypothesis.\n",
    "\n",
    "Read more about the t-test in [this article](http://b.link/test50) and [this Quora](http://b.link/unpaired97). Make sure you understand when to use which type of t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One tailed t-test \n",
    "In a packing plant, a machine packs cartons with jars. It is supposed that a new machine will pack faster on the average than the machine currently used. To test that hypothesis, the times it takes each machine to pack ten cartons are recorded. The results, in seconds, are shown in the tables in the file files_for_lab/ttest_machine.xlsx. Assume that there is sufficient evidence to conduct the t test, does the data provide sufficient evidence to show if one machine is better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_machine = pd.read_table('ttest_machine.txt',delimiter = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New_machine</th>\n",
       "      <th>Old_machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.1</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.3</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.8</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.4</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New_machine  Old_machine\n",
       "0         42.1         42.7\n",
       "1         41.0         43.6\n",
       "2         41.3         43.8\n",
       "3         41.8         43.3\n",
       "4         42.4         42.5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0 = New machine >= Old machine\n",
    "# H1 = New machine < Old machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-3.397230706117603, pvalue=0.0032422494663179747)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.ttest_ind(ttest_machine['New_machine'], ttest_machine['Old_machine'], equal_var=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value is below 0.05 . Hence  the null-hypothesis is rejected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset\n",
    "\n",
    "In this challenge we will work on the Pokemon dataset you have already used. The goal is to test whether different groups of pokemon (e.g. Legendary vs Normal, Generation 1 vs 2, single-type vs dual-type) have different stats (e.g. HP, Attack, Defense, etc.). Use pokemon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "pokemon = pd.read_csv('./pokemon.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>298</td>\n",
       "      <td>Azurill</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       #     Name  Type 1 Type 2  Total  HP  Attack  Defense  Sp. Atk  \\\n",
       "322  298  Azurill  Normal  Fairy    190  50      20       40       20   \n",
       "\n",
       "     Sp. Def  Speed  Generation  Legendary  \n",
       "322       40     20           3      False  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we want to define a function with which we can test the means of a feature set of two samples. \n",
    "\n",
    "In the next cell you'll see the annotations of the Python function that explains what this function does and its arguments and returned value. This type of annotation is called **docstring** which is a convention used among Python developers. The docstring convention allows developers to write consistent tech documentations for their codes so that others can read. It also allows some websites to automatically parse the docstrings and display user-friendly documentations.\n",
    "\n",
    "Follow the specifications of the docstring and complete the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `t_test_features` function, conduct t-test for Lengendary vs non-Legendary pokemons.\n",
    "\n",
    "*Hint: your output should look like below:*\n",
    "\n",
    "```\n",
    "{'HP': 1.0026911708035284e-13,\n",
    " 'Attack': 2.520372449236646e-16,\n",
    " 'Defense': 4.8269984949193316e-11,\n",
    " 'Sp. Atk': 1.5514614112239812e-21,\n",
    " 'Sp. Def': 2.2949327864052826e-15,\n",
    " 'Speed': 1.049016311882451e-18,\n",
    " 'Total': 9.357954335957446e-47}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True]\n"
     ]
    }
   ],
   "source": [
    "print(pokemon['Legendary'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "legendary_pokemon = pokemon.loc[pokemon['Legendary'] == True]\n",
    "non_legendary_pokemon = pokemon.loc[pokemon['Legendary'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_features(s1, s2, features=['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Total']):\n",
    "    results = {}\n",
    "    for feature in features:\n",
    "        statistic, pvalue = st.ttest_ind(s1[feature],s2[feature])   \n",
    "        results[feature] = pvalue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 3.330647684846191e-15,\n",
       " 'Attack': 7.827253003205333e-24,\n",
       " 'Defense': 1.5842226094427255e-12,\n",
       " 'Sp. Atk': 6.314915770427266e-41,\n",
       " 'Sp. Def': 1.8439809580409333e-26,\n",
       " 'Speed': 2.3540754436897763e-21,\n",
       " 'Total': 3.0952457469652825e-52}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_features(legendary_pokemon,non_legendary_pokemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the test results above, what conclusion can you make? Do Legendary and non-Legendary pokemons have significantly different stats on each feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your comment here\n",
    "\n",
    "\n",
    "\n",
    "- H0: legendary pokemons and non-legendary pokemons are equal\n",
    "- H1: legendary pokemons and non-legendary pokemons are not equal\n",
    "\n",
    "\n",
    "- p-value is less than 0.05, so we can declare the null-hypothesis is rejected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, conduct t-test for Generation 1 and Generation 2 pokemons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "generation_1_pokemon = pokemon.loc[pokemon['Generation'] == 1]\n",
    "generation_2_pokemon = pokemon.loc[pokemon['Generation'] == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.13791881412813622,\n",
       " 'Attack': 0.24050968418101457,\n",
       " 'Defense': 0.5407630349194362,\n",
       " 'Sp. Atk': 0.141197881763315,\n",
       " 'Sp. Def': 0.16781226231606386,\n",
       " 'Speed': 0.0028356954812578704,\n",
       " 'Total': 0.559914064901444}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_generations(generation_1_pokemon,generation_2_pokemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your comment here\n",
    "\n",
    "\n",
    "- H0: Generation1 pokemons and Generation2 pokemons are equal\n",
    "- H1: Generation1 pokemons and Generation2 pokemons are not equal\n",
    "\n",
    "\n",
    "-  except 'Speed',p-value is above 0.05 we do not reject the null-hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare pokemons who have single type vs those having two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 0.11060643144431853,\n",
       " 'Attack': 0.00015741395666164396,\n",
       " 'Defense': 3.250594205757004e-08,\n",
       " 'Sp. Atk': 0.0001454917404035147,\n",
       " 'Sp. Def': 0.00010893304795534396,\n",
       " 'Speed': 0.024051410794037463,\n",
       " 'Total': 1.1749035008828668e-07}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "# Your code here\n",
    "# print(pokemon['Type 1'].isna().sum())\n",
    "single_type_pokemon = pokemon.loc[pokemon['Type 2'].isna()]\n",
    "dual_type_pokemon = pokemon.loc[pokemon['Type 2'].notnull()]\n",
    "\n",
    "t_test_features(single_type_pokemon, dual_type_pokemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your comment here\n",
    "\n",
    "- H0: Type1 and Type2 pokemons are equal\n",
    "- H1: Type1 and Type2 pokemons are not equal\n",
    "\n",
    "-  except 'Defense' and 'Total',p-value is above 0.05 we do not reject the null-hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we want to compare whether there are significant differences of `Attack` vs `Defense`  and  `Sp. Atk` vs `Sp. Def` of all pokemons. Please write your code below.\n",
    "\n",
    "*Hint: are you comparing different populations or the same population?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=4.325566393330478, pvalue=1.7140303479358558e-05)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "st.ttest_rel(pokemon['Attack'], pokemon['Defense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.853986188453353, pvalue=0.3933685997548122)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.ttest_rel(pokemon['Sp. Atk'], pokemon['Sp. Def'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What conclusions can you make?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your comment here\n",
    "\n",
    "\n",
    "- H0 - The null hypothesis is that both defense and attack scores are equal\n",
    "- H1 - The alternative hypothesis is that both the scores are unequal.\n",
    "- for 'Attack' vs 'Defense' the p_value is less than 0.05 ,hence the null-hypothesis is rejected.\n",
    "\n",
    "- H0 -  There is no difference at the mean of differences\n",
    "- H1 -  There is a difference at the mean of differences\n",
    "\n",
    "- for  'Sp. Atk' vs 'Sp. Def' the p_value is greater than 0.05 ,hence  we do not reject the null-hypothesis. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
